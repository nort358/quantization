# quantization
Эксперимент возможностей сжатия полносвязной нейронной сети методами статической и динамической квантизации в зависимости от архитектуры - глубины и ширины - нейронной сети.

Главная предпосылка квантизации: операции во FLOAT32 — происходят дольше и требуют больше памяти, чем в INT8. Идея: перевести все FLOAT32 в обычные INT8. Ожидается, что работа нейросети должна стать быстрее, потому что операции быстрее происходят на INT8, а также занимать примерно в четыре раза меньше памяти. На практике квантизация дает значительный прирост по скорости инференса на широких и глубоких архитектурах, а также на сверточных нейросетях. Skip-сonnections также способствуют сжатию сети при квантизации

Исследованы разные ширина и глубина полносвязной сети, на маленьких сетях операции перевода чисел в другой тип данных занимали больше времени, чем можно сэкономить, производя матричные расчеты в INT8
